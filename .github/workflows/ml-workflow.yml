name: ML Pipeline CI/CD

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'MLProject/**'
      - '.github/workflows/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'MLProject/**'
  workflow_dispatch:
    inputs:
      model_type:
        description: 'Model to train'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - random_forest
          - linear_regression
          - decision_tree

jobs:
  test-and-train:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Set up Conda
      uses: conda-incubator/setup-miniconda@v2
      with:
        auto-update-conda: true
        python-version: '3.9'
        environment-file: MLProject/conda.yaml
        activate-environment: weather_prediction_env
    
    - name: Verify environment
      shell: bash -el {0}
      run: |
        conda info
        conda list
    
    - name: Install additional dependencies
      shell: bash -el {0}
      run: |
        pip install mlflow click
    
    - name: Check data file
      run: |
        if [ -f "MLProject/weatherdata_preprocessing.csv" ]; then
          echo "âœ“ Data file found"
          head -5 MLProject/weatherdata_preprocessing.csv
        else
          echo "âš ï¸  Data file not found - creating sample data"
          python -c "
import pandas as pd
import numpy as np

# Generate sample weather data
np.random.seed(42)
n_samples = 1000

data = {
    'Location': np.random.choice(['CityA', 'CityB', 'CityC', 'CityD'], n_samples),
    'Temperature_C': np.random.normal(25, 10, n_samples),
    'Humidity_pct': np.random.uniform(30, 90, n_samples),
    'Precipitation_mm': np.random.exponential(2, n_samples),
    'Wind_Speed_kmh': np.random.uniform(0, 50, n_samples)
}

df = pd.DataFrame(data)
df.to_csv('MLProject/weatherdata_preprocessing.csv', index=False)
print('Sample data created successfully')
"
        fi
    
    - name: Run MLflow project - Data validation
      shell: bash -el {0}
      run: |
        cd MLProject
        python -c "
import pandas as pd
df = pd.read_csv('weatherdata_preprocessing.csv')
print('Data shape:', df.shape)
print('Columns:', df.columns.tolist())
print('Data types:')
print(df.dtypes)
print('Missing values:')
print(df.isnull().sum())
"
    
    - name: Run MLflow project - Model training
      shell: bash -el {0}
      run: |
        cd MLProject
        export MLFLOW_TRACKING_URI=file:./mlruns
        
        # Determine which model to train
        if [ "${{ github.event.inputs.model_type }}" != "" ]; then
          MODEL_TYPE="${{ github.event.inputs.model_type }}"
        else
          MODEL_TYPE="all"
        fi
        
        echo "Training model type: $MODEL_TYPE"
        
        # Run the training
        python modelling.py --model $MODEL_TYPE --data_path weatherdata_preprocessing.csv
    
    - name: Generate training report
      shell: bash -el {0}
      run: |
        cd MLProject
        python -c "
import mlflow
import pandas as pd
import os

# Set tracking URI
mlflow.set_tracking_uri('file:./mlruns')

# Get the experiment
experiment = mlflow.get_experiment_by_name('Weather_Prediction_Experiment')
if experiment:
    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])
    if not runs.empty:
        print('=== Training Report ===')
        print(f'Total runs: {len(runs)}')
        print()
        
        # Sort by test_r2 descending
        if 'metrics.test_r2' in runs.columns:
            runs_sorted = runs.sort_values('metrics.test_r2', ascending=False)
            
            print('Best performing models:')
            for idx, row in runs_sorted.head(3).iterrows():
                print(f'Model: {row.get(\"params.model_type\", \"Unknown\")}')
                print(f'  Test RÂ²: {row.get(\"metrics.test_r2\", \"N/A\"):.4f}')
                print(f'  Test MSE: {row.get(\"metrics.test_mse\", \"N/A\"):.4f}')
                print(f'  Test MAE: {row.get(\"metrics.test_mae\", \"N/A\"):.4f}')
                print()
        else:
            print('No test metrics found in runs')
            print('Available columns:', runs.columns.tolist())
    else:
        print('No runs found in experiment')
else:
    print('Experiment not found')
"
    
    - name: Save training results to file
      shell: bash -el {0}
      run: |
        cd MLProject
        python -c "
import mlflow
import pandas as pd
import json
from datetime import datetime

# Set tracking URI
mlflow.set_tracking_uri('file:./mlruns')

# Get the experiment
experiment = mlflow.get_experiment_by_name('Weather_Prediction_Experiment')
results = {
    'timestamp': datetime.now().isoformat(),
    'experiment_name': 'Weather_Prediction_Experiment',
    'total_runs': 0,
    'best_models': []
}

if experiment:
    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])
    if not runs.empty:
        results['total_runs'] = len(runs)
        
        if 'metrics.test_r2' in runs.columns:
            runs_sorted = runs.sort_values('metrics.test_r2', ascending=False)
            
            for idx, row in runs_sorted.head(3).iterrows():
                model_result = {
                    'model_name': row.get('params.model_type', 'Unknown'),
                    'test_r2': float(row.get('metrics.test_r2', 0)),
                    'test_mse': float(row.get('metrics.test_mse', 0)),
                    'test_mae': float(row.get('metrics.test_mae', 0)),
                    'run_id': row.get('run_id', '')
                }
                results['best_models'].append(model_result)

# Save results to JSON file
with open('training_results.json', 'w') as f:
    json.dump(results, f, indent=2)
    
print('Training results saved to training_results.json')
"
    
    - name: Upload MLflow artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: mlflow-artifacts-${{ github.run_number }}
        path: |
          MLProject/mlruns/
          MLProject/*.png
          MLProject/training_results.json
        retention-days: 30
    
    - name: Upload training logs
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: training-logs-${{ github.run_number }}
        path: |
          MLProject/*.log
        retention-days: 7
    
    - name: Create Pull Request Comment (if PR)
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = './MLProject/training_results.json';
          
          if (fs.existsSync(path)) {
            const results = JSON.parse(fs.readFileSync(path, 'utf8'));
            
            let comment = `## ðŸ¤– ML Pipeline Results\n\n`;
            comment += `**Experiment:** ${results.experiment_name}\n`;
            comment += `**Total Runs:** ${results.total_runs}\n`;
            comment += `**Timestamp:** ${results.timestamp}\n\n`;
            
            if (results.best_models.length > 0) {
              comment += `### ðŸ† Best Performing Models:\n\n`;
              results.best_models.forEach((model, index) => {
                comment += `**${index + 1}. ${model.model_name}**\n`;
                comment += `- Test RÂ²: ${model.test_r2.toFixed(4)}\n`;
                comment += `- Test MSE: ${model.test_mse.toFixed(4)}\n`;
                comment += `- Test MAE: ${model.test_mae.toFixed(4)}\n\n`;
              });
            }
            
            comment += `\nðŸ“Š Check the artifacts for detailed MLflow runs and visualizations.`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          }
