name: MLflow Weather Prediction CI

# Kapan workflow ini jalan
on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:  # Bisa dijalankan manual

jobs:
  train-model:
    runs-on: ubuntu-latest
    
    steps:
    # Step 1: Download kode dari repository
    - name: Checkout Repository
      uses: actions/checkout@v4
      
    # Step 2: Setup Python dengan Miniconda
    - name: Setup Miniconda
      uses: conda-incubator/setup-miniconda@v3
      with:
        activate-environment: ml-env
        environment-file: conda.yaml
        python-version: 3.9
        auto-activate-base: false
        
    # Step 3: Cek environment berhasil dibuat
    - name: Verify Environment Setup
      shell: bash -l {0}
      run: |
        echo "=== Checking Python and Conda ==="
        python --version
        conda --version
        conda list | head -20
        
    # Step 4: Install MLflow dan dependencies tambahan
    - name: Install MLflow and Additional Dependencies
      shell: bash -l {0}
      run: |
        echo "=== Installing MLflow ==="
        pip install mlflow
        pip install matplotlib seaborn
        echo "=== Installed packages ==="
        pip list | grep -E "(mlflow|matplotlib|seaborn)"
        
    # Step 5: Buat file data dummy (karena path asli ga ada di CI)
    - name: Create Sample Data
      shell: bash -l {0}
      run: |
        echo "=== Creating sample weather data ==="
        python -c "
import pandas as pd
import numpy as np

# Buat data dummy yang mirip dengan data asli
np.random.seed(42)
n_samples = 1000

# Generate sample data
data = {
    'Location': np.random.choice(['Jakarta', 'Bandung', 'Surabaya', 'Medan', 'Makassar'], n_samples),
    'Temperature_C': np.random.normal(27, 5, n_samples),
    'Humidity_pct': np.random.uniform(60, 90, n_samples),
    'Precipitation_mm': np.random.exponential(2, n_samples),
    'Wind_Speed_kmh': np.random.uniform(5, 25, n_samples)
}

df = pd.DataFrame(data)
df['Temperature_C'] = np.round(df['Temperature_C'], 1)
df['Humidity_pct'] = np.round(df['Humidity_pct'], 1)
df['Precipitation_mm'] = np.round(df['Precipitation_mm'], 2)
df['Wind_Speed_kmh'] = np.round(df['Wind_Speed_kmh'], 1)

# Simpan ke file
df.to_csv('weatherdata_preprocessing.csv', index=False)
print(f'Sample data created: {df.shape}')
print(df.head())
"
        
    # Step 6: Modifikasi script untuk CI environment
    - name: Prepare Modeling Script for CI
      shell: bash -l {0}
      run: |
        echo "=== Modifying modelling.py for CI ==="
        # Buat versi modifikasi dari script asli
        cat > modelling_ci.py << 'EOF'
import mlflow
import mlflow.sklearn
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler, LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

def load_and_prepare_data():
    """
    Load dan prepare data untuk modeling
    """
    print("Loading and preparing data...")
    
    # Load data dari CSV file (path disesuaikan untuk CI)
    csv_path = "weatherdata_preprocessing.csv"
    
    try:
        df = pd.read_csv(csv_path)
        print(f"Data loaded successfully from: {csv_path}")
        print(f"Shape: {df.shape}")
        print(f"Columns: {df.columns.tolist()}")
        
    except FileNotFoundError:
        print(f"Error: File not found at {csv_path}")
        return None, None, None, None, None
    except Exception as e:
        print(f"Error loading data: {str(e)}")
        return None, None, None, None, None
    
    # Preprocessing
    if 'Location' in df.columns:
        le = LabelEncoder()
        df['Location_encoded'] = le.fit_transform(df['Location'])
    
    # Features and target
    feature_columns = ['Location_encoded', 'Humidity_pct', 'Precipitation_mm', 'Wind_Speed_kmh']
    X = df[feature_columns]
    y = df['Temperature_C']
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    print(f"Data prepared: {X.shape[0]} samples, {X.shape[1]} features")
    return X_train, X_test, y_train, y_test, feature_columns

def train_model(model, model_name, X_train, X_test, y_train, y_test, feature_columns):
    """
    Train model dengan MLflow tracking
    """
    with mlflow.start_run(run_name=f"{model_name}_experiment"):
        
        # Enable autolog untuk scikit-learn
        mlflow.sklearn.autolog()
        
        print(f"\n--- Training {model_name} ---")
        
        # Train model
        model.fit(X_train, y_train)
        
        # Predictions
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)
        
        # Metrics
        train_mse = mean_squared_error(y_train, y_train_pred)
        test_mse = mean_squared_error(y_test, y_test_pred)
        train_r2 = r2_score(y_train, y_train_pred)
        test_r2 = r2_score(y_test, y_test_pred)
        train_mae = mean_absolute_error(y_train, y_train_pred)
        test_mae = mean_absolute_error(y_test, y_test_pred)
        
        # Log metrics
        mlflow.log_metric("train_mse", train_mse)
        mlflow.log_metric("test_mse", test_mse)
        mlflow.log_metric("train_r2", train_r2)
        mlflow.log_metric("test_r2", test_r2)
        mlflow.log_metric("train_mae", train_mae)
        mlflow.log_metric("test_mae", test_mae)
        
        # Log parameters
        mlflow.log_param("model_type", model_name)
        mlflow.log_param("n_features", len(feature_columns))
        mlflow.log_param("train_size", len(X_train))
        mlflow.log_param("test_size", len(X_test))
        
        # Create visualization (simplified for CI)
        plt.figure(figsize=(10, 4))
        plt.subplot(1, 2, 1)
        plt.scatter(y_test, y_test_pred, alpha=0.6)
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
        plt.xlabel('Actual Temperature')
        plt.ylabel('Predicted Temperature')
        plt.title(f'{model_name} - Actual vs Predicted')
        
        plt.subplot(1, 2, 2)
        residuals = y_test - y_test_pred
        plt.scatter(y_test_pred, residuals, alpha=0.6)
        plt.axhline(y=0, color='r', linestyle='--')
        plt.xlabel('Predicted Temperature')
        plt.ylabel('Residuals')
        plt.title(f'{model_name} - Residuals')
        
        plt.tight_layout()
        plt.savefig(f'{model_name}_evaluation.png')
        mlflow.log_artifact(f'{model_name}_evaluation.png')
        plt.close()
        
        # Print results
        print(f"Train MSE: {train_mse:.4f}")
        print(f"Test MSE: {test_mse:.4f}")
        print(f"Train R²: {train_r2:.4f}")
        print(f"Test R²: {test_r2:.4f}")
        print(f"Test MAE: {test_mae:.4f}")
        
        return model

def main():
    """
    Main function untuk menjalankan eksperimen
    """
    print("=== MLflow Weather Prediction Experiment ===")
    
    # Set MLflow tracking URI ke local
    mlflow.set_tracking_uri("file:./mlruns")
    
    # Set experiment name
    experiment_name = "Weather_Prediction_CI_Experiment"
    mlflow.set_experiment(experiment_name)
    
    print(f"MLflow Tracking URI: {mlflow.get_tracking_uri()}")
    print(f"Experiment: {experiment_name}")
    
    # Load data
    X_train, X_test, y_train, y_test, feature_columns = load_and_prepare_data()
    
    if X_train is None:
        print("Data loading failed. Exiting...")
        return
    
    # Define models
    models = {
        "RandomForest": RandomForestRegressor(n_estimators=10, random_state=42),  # Reduced for CI
        "LinearRegression": LinearRegression(),
        "DecisionTree": DecisionTreeRegressor(max_depth=5, random_state=42)  # Limited depth for CI
    }
    
    # Train models
    trained_models = {}
    for model_name, model in models.items():
        try:
            trained_model = train_model(model, model_name, X_train, X_test, y_train, y_test, feature_columns)
            trained_models[model_name] = trained_model
            print(f"✅ {model_name} trained successfully")
        except Exception as e:
            print(f"❌ Error training {model_name}: {str(e)}")
    
    print("\n=== Experiment Completed ===")
    print(f"Total models trained: {len(trained_models)}")
    
    # Export summary
    with open('training_summary.txt', 'w') as f:
        f.write("=== MLflow Training Summary ===\n")
        f.write(f"Models trained: {len(trained_models)}\n")
        f.write(f"Models: {list(trained_models.keys())}\n")
        f.write(f"Features used: {feature_columns}\n")
        f.write(f"Training samples: {len(X_train)}\n")
        f.write(f"Test samples: {len(X_test)}\n")
    
    print("Training summary saved to training_summary.txt")

if __name__ == "__main__":
    main()
EOF
        echo "✅ Modified script created as modelling_ci.py"
        
    # Step 7: Run the ML training
    - name: Run MLflow Training
      shell: bash -l {0}
      run: |
        echo "=== Running MLflow Training ==="
        python modelling_ci.py
        
    # Step 8: Check results
    - name: Check Training Results
      shell: bash -l {0}
      run: |
        echo "=== Checking Training Results ==="
        ls -la
        
        # Check MLflow artifacts
        if [ -d "mlruns" ]; then
          echo "✅ MLflow runs directory created"
          find mlruns -name "*.png" -o -name "*.pkl" -o -name "*.json" | head -10
        fi
        
        # Check plots
        if ls *.png 1> /dev/null 2>&1; then
          echo "✅ Visualization plots created:"
          ls -la *.png
        fi
        
        # Check summary
        if [ -f "training_summary.txt" ]; then
          echo "✅ Training summary:"
          cat training_summary.txt
        fi
        
    # Step 9: Upload artifacts
    - name: Upload Training Artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: mlflow-training-results
        path: |
          mlruns/
          *.png
          *.txt
          *.csv
        retention-days: 30
        
    # Step 10: Create final report
    - name: Create Final Report
      shell: bash -l {0}
      if: always()
      run: |
        echo "# MLflow CI Training Report" > final_report.md
        echo "" >> final_report.md
        echo "## Workflow Summary" >> final_report.md
        echo "- **Date**: $(date)" >> final_report.md
        echo "- **Status**: ${{ job.status }}" >> final_report.md
        echo "- **Repository**: ${{ github.repository }}" >> final_report.md
        echo "" >> final_report.md
        echo "## Training Results" >> final_report.md
        if [ -f "training_summary.txt" ]; then
          echo "### Training Summary" >> final_report.md
          echo '```' >> final_report.md
          cat training_summary.txt >> final_report.md
          echo '```' >> final_report.md
        fi
        echo "" >> final_report.md
        echo "## Generated Files" >> final_report.md
        echo "- MLflow experiments: mlruns/" >> final_report.md
        echo "- Model visualizations: *.png files" >> final_report.md
        echo "- Training data: weatherdata_preprocessing.csv" >> final_report.md
        echo "" >> final_report.md
        echo "---" >> final_report.md
        echo "*Generated by GitHub Actions*" >> final_report.md
        
        echo "=== Final Report ==="
        cat final_report.md
        
    - name: Upload Final Report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: final-training-report
        path: final_report.md
        retention-days: 30
